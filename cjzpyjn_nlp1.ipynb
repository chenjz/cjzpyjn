{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Practice 1: computing text similarities using gensim and nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-03-2016 19:15:21 - cjzpy_load_logging - load_logging_json - INFO - Loading my universal log service: cjzpy_logging.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported ColorizingStreamHandler from logutils\n",
      "Failed importing ColorizingStreamHandler from logutils, using logging.StreamHandler()\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "import sys, logging\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# all output goes to logs \n",
    "sys.path.append('~/logs')\n",
    "import cjzpy_load_logging\n",
    "#cjzpy_load_logging.load_logging_json(default_level=logging.INFO)\n",
    "cjzpy_load_logging.load_logging_json(default_level=logging.DEBUG)\n",
    "logger = logging.getLogger(sys._getframe().f_code.co_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-03-2016 19:16:05 - <ipython-input-76-954f0d7d5eb2> - <module> - DEBUG - hello gensim\n",
      "25-03-2016 19:16:05 - <ipython-input-76-954f0d7d5eb2> - <module> - INFO - hello NLP practice 1\n"
     ]
    }
   ],
   "source": [
    "logger.debug('hello gensim')\n",
    "logger.info('hello NLP practice 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gensim4texts(logger, texts, query, nTopic):\n",
    "    logger.info('This is %s', sys._getframe().f_code.co_name)\n",
    "    logger.debug('texts: %s', texts)\n",
    "    # In BoW representation, each document is represented by one vector where each vector element represents a question-answer pair, in the style of: How many times does the word system appear in the document? The mapping between the questions and ids is called a dictionary\n",
    "    dictionary = gensim.corpora.Dictionary(texts)\n",
    "    logger.debug('dictionary.token2id: %s', dictionary.token2id)\n",
    "    # To actually convert tokenized documents to vectors\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    # gensim.corpora.MmCorpus.serialize('corpus_tmp.mm', corpus) # store to disk, for later use\n",
    "    logger.debug('corpus: %s', corpus)\n",
    "    tfidf = gensim.models.TfidfModel(corpus)\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "    for doc in corpus_tfidf:\n",
    "        logger.debug('corpus_tfidf.doc: %s', doc)\n",
    "    logger.debug('tfidf.dfs: %s', tfidf.dfs)\n",
    "    logger.debug('tfidf.idfs: %s', tfidf.idfs)\n",
    "    lsi = gensim.models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=nTopic)\n",
    "    lsi.print_topics(2)\n",
    "    corpus_lsi = lsi[corpus_tfidf]\n",
    "    for doc in corpus_lsi:\n",
    "        logger.debug('copus_lsi.doc: %s', doc)\n",
    "\n",
    "    lda = gensim.models.LdaModel(corpus_tfidf, id2word=dictionary, num_topics=nTopic)\n",
    "    lda.print_topics(2)\n",
    "    index = gensim.similarities.MatrixSimilarity(lsi[corpus])\n",
    "    #query_bow = dictionary.doc2bow(query.lower().split())\n",
    "    query_bow = dictionary.doc2bow(query)\n",
    "    logger.debug('query_bow: %s', query_bow)\n",
    "    query_lsi = lsi[query_bow]\n",
    "    logger.debug('query_lsi: %s', query_lsi)\n",
    "    sims = index[query_lsi]\n",
    "    logger.debug('sims: %s', list(enumerate(sims)))\n",
    "\n",
    "    sort_sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "    logger.info('sort_sims: %s', sort_sims)\n",
    "    return sort_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-03-2016 19:16:14 - <ipython-input-77-a79ba582be37> - <module> - INFO - This is gensim4texts\n",
      "25-03-2016 19:16:14 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - texts: [['shipment', 'of', 'gold', 'damaged', 'in', 'a', 'fire'], ['delivery', 'of', 'silver', 'arrived', 'in', 'a', 'silver', 'truck'], ['shipment', 'of', 'gold', 'arrived', 'in', 'a', 'truck']]\n",
      "25-03-2016 19:16:14 - dictionary - gensim.corpora.dictionary - INFO - adding document #0 to Dictionary(0 unique tokens: [])\n",
      "25-03-2016 19:16:14 - dictionary - gensim.corpora.dictionary - INFO - built Dictionary(11 unique tokens: ['delivery', 'a', 'silver', 'shipment', 'damaged']...) from 3 documents (total 22 corpus positions)\n",
      "25-03-2016 19:16:14 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - dictionary.token2id: {'delivery': 7, 'a': 3, 'silver': 8, 'shipment': 1, 'damaged': 2, 'in': 4, 'of': 0, 'fire': 6, 'gold': 5, 'arrived': 9, 'truck': 10}\n",
      "25-03-2016 19:16:14 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - corpus: [[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)], [(0, 1), (3, 1), (4, 1), (7, 1), (8, 2), (9, 1), (10, 1)], [(0, 1), (1, 1), (3, 1), (4, 1), (5, 1), (9, 1), (10, 1)]]\n",
      "25-03-2016 19:16:14 - tfidfmodel - gensim.models.tfidfmodel - INFO - collecting document frequencies\n",
      "25-03-2016 19:16:14 - tfidfmodel - gensim.models.tfidfmodel - INFO - PROGRESS: processing document #0\n",
      "25-03-2016 19:16:14 - tfidfmodel - gensim.models.tfidfmodel - INFO - calculating IDF weights for 3 documents and 10 features (21 matrix non-zeros)\n",
      "25-03-2016 19:16:14 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - corpus_tfidf.doc: [(1, 0.2448297500958463), (2, 0.6633689723434505), (5, 0.2448297500958463), (6, 0.6633689723434505)]\n",
      "25-03-2016 19:16:14 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - corpus_tfidf.doc: [(7, 0.4355066251613605), (8, 0.871013250322721), (9, 0.16073253746956623), (10, 0.16073253746956623)]\n",
      "25-03-2016 19:16:14 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - corpus_tfidf.doc: [(1, 0.5), (5, 0.5), (9, 0.5), (10, 0.5)]\n",
      "25-03-2016 19:16:14 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - tfidf.dfs: {0: 3, 1: 2, 2: 1, 3: 3, 4: 3, 5: 2, 6: 1, 7: 1, 8: 1, 9: 2, 10: 2}\n",
      "25-03-2016 19:16:14 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - tfidf.idfs: {0: 0.0, 1: 0.5849625007211562, 2: 1.5849625007211563, 3: 0.0, 4: 0.0, 5: 0.5849625007211562, 6: 1.5849625007211563, 7: 1.5849625007211563, 8: 1.5849625007211563, 9: 0.5849625007211562, 10: 0.5849625007211562}\n",
      "25-03-2016 19:16:14 - lsimodel - gensim.models.lsimodel - INFO - using serial LSI version on this node\n",
      "25-03-2016 19:16:14 - lsimodel - gensim.models.lsimodel - INFO - updating model with new documents\n",
      "25-03-2016 19:16:14 - lsimodel - gensim.models.lsimodel - INFO - preparing a new chunk of documents\n",
      "25-03-2016 19:16:14 - lsimodel - gensim.models.lsimodel - DEBUG - converting corpus to csc format\n",
      "25-03-2016 19:16:14 - lsimodel - gensim.models.lsimodel - INFO - using 100 extra samples and 2 power iterations\n",
      "25-03-2016 19:16:14 - lsimodel - gensim.models.lsimodel - INFO - 1st phase: constructing (11, 102) action matrix\n",
      "25-03-2016 19:16:14 - lsimodel - gensim.models.lsimodel - INFO - orthonormalizing (11, 102) action matrix\n",
      "25-03-2016 19:16:14 - matutils - gensim.matutils - DEBUG - computing QR of (11, 102) dense matrix\n",
      "25-03-2016 19:16:14 - lsimodel - gensim.models.lsimodel - DEBUG - running 2 power iterations\n",
      "25-03-2016 19:16:14 - matutils - gensim.matutils - DEBUG - computing QR of (11, 11) dense matrix\n",
      "25-03-2016 19:16:14 - matutils - gensim.matutils - DEBUG - computing QR of (11, 11) dense matrix\n",
      "25-03-2016 19:16:14 - lsimodel - gensim.models.lsimodel - INFO - 2nd phase: running dense svd on (11, 3) matrix\n",
      "25-03-2016 19:16:14 - lsimodel - gensim.models.lsimodel - INFO - computing the final decomposition\n",
      "25-03-2016 19:16:14 - lsimodel - gensim.models.lsimodel - INFO - keeping 2 factors (discarding 23.571% of energy spectrum)\n",
      "25-03-2016 19:16:14 - lsimodel - gensim.models.lsimodel - INFO - processed documents up to #3\n",
      "25-03-2016 19:16:14 - lsimodel - gensim.models.lsimodel - INFO - topic #0(1.137): 0.438*\"shipment\" + 0.438*\"gold\" + 0.366*\"truck\" + 0.366*\"arrived\" + 0.345*\"fire\" + 0.345*\"damaged\" + 0.297*\"silver\" + 0.149*\"delivery\" + -0.000*\"of\" + 0.000*\"a\"\n",
      "25-03-2016 19:16:14 - lsimodel - gensim.models.lsimodel - INFO - topic #1(1.000): 0.728*\"silver\" + 0.364*\"delivery\" + -0.364*\"damaged\" + -0.364*\"fire\" + 0.134*\"truck\" + 0.134*\"arrived\" + -0.134*\"shipment\" + -0.134*\"gold\" + -0.000*\"of\" + -0.000*\"a\"\n",
      "25-03-2016 19:16:14 - lsimodel - gensim.models.lsimodel - INFO - topic #0(1.137): 0.438*\"shipment\" + 0.438*\"gold\" + 0.366*\"truck\" + 0.366*\"arrived\" + 0.345*\"fire\" + 0.345*\"damaged\" + 0.297*\"silver\" + 0.149*\"delivery\" + -0.000*\"of\" + 0.000*\"a\"\n",
      "25-03-2016 19:16:14 - lsimodel - gensim.models.lsimodel - INFO - topic #1(1.000): 0.728*\"silver\" + 0.364*\"delivery\" + -0.364*\"damaged\" + -0.364*\"fire\" + 0.134*\"truck\" + 0.134*\"arrived\" + -0.134*\"shipment\" + -0.134*\"gold\" + -0.000*\"of\" + -0.000*\"a\"\n",
      "25-03-2016 19:16:14 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - copus_lsi.doc: [(0, 0.67211468809878716), (1, -0.54880682119355884)]\n",
      "25-03-2016 19:16:14 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - copus_lsi.doc: [(0, 0.4412482520869766), (1, 0.83594920480339074)]\n",
      "25-03-2016 19:16:14 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - copus_lsi.doc: [(0, 0.80401378963792725)]\n",
      "25-03-2016 19:16:14 - ldamodel - gensim.models.ldamodel - INFO - using symmetric alpha at 0.5\n",
      "25-03-2016 19:16:14 - ldamodel - gensim.models.ldamodel - INFO - using symmetric eta at 0.5\n",
      "25-03-2016 19:16:14 - ldamodel - gensim.models.ldamodel - INFO - using serial LDA version on this node\n",
      "25-03-2016 19:16:14 - ldamodel - gensim.models.ldamodel - INFO - running online LDA training, 2 topics, 1 passes over the supplied corpus of 3 documents, updating model once every 3 documents, evaluating perplexity every 3 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "25-03-2016 19:16:14 - ldamodel - gensim.models.ldamodel - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "25-03-2016 19:16:14 - ldamodel - gensim.models.ldamodel - DEBUG - bound: at document #0\n",
      "25-03-2016 19:16:14 - ldamodel - gensim.models.ldamodel - INFO - -5.377 per-word bound, 41.5 perplexity estimate based on a held-out corpus of 3 documents with 5 words\n",
      "25-03-2016 19:16:14 - ldamodel - gensim.models.ldamodel - INFO - PROGRESS: pass 0, at document #3/3\n",
      "25-03-2016 19:16:14 - ldamodel - gensim.models.ldamodel - DEBUG - performing inference on a chunk of 3 documents\n",
      "25-03-2016 19:16:14 - ldamodel - gensim.models.ldamodel - DEBUG - 3/3 documents converged within 50 iterations\n",
      "25-03-2016 19:16:14 - ldamodel - gensim.models.ldamodel - DEBUG - updating topics\n",
      "25-03-2016 19:16:14 - ldamodel - gensim.models.ldamodel - INFO - topic #0 (0.500): 0.129*silver + 0.111*truck + 0.106*arrived + 0.106*gold + 0.098*shipment + 0.095*fire + 0.094*delivery + 0.084*damaged + 0.058*of + 0.058*a\n",
      "25-03-2016 19:16:14 - ldamodel - gensim.models.ldamodel - INFO - topic #1 (0.500): 0.120*damaged + 0.115*shipment + 0.107*fire + 0.106*gold + 0.097*silver + 0.095*arrived + 0.090*truck + 0.079*delivery + 0.064*of + 0.064*a\n",
      "25-03-2016 19:16:14 - ldamodel - gensim.models.ldamodel - INFO - topic diff=0.397648, rho=1.000000\n",
      "25-03-2016 19:16:14 - ldamodel - gensim.models.ldamodel - INFO - topic #0 (0.500): 0.129*silver + 0.111*truck + 0.106*arrived + 0.106*gold + 0.098*shipment + 0.095*fire + 0.094*delivery + 0.084*damaged + 0.058*of + 0.058*a\n",
      "25-03-2016 19:16:14 - ldamodel - gensim.models.ldamodel - INFO - topic #1 (0.500): 0.120*damaged + 0.115*shipment + 0.107*fire + 0.106*gold + 0.097*silver + 0.095*arrived + 0.090*truck + 0.079*delivery + 0.064*of + 0.064*a\n",
      "25-03-2016 19:16:14 - docsim - gensim.similarities.docsim - WARNING - scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "25-03-2016 19:16:14 - docsim - gensim.similarities.docsim - INFO - creating matrix with 3 documents and 2 features\n",
      "25-03-2016 19:16:14 - docsim - gensim.similarities.docsim - DEBUG - PROGRESS: at document #0/3\n",
      "25-03-2016 19:16:14 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - query_bow: [(5, 1), (8, 1), (10, 1)]\n",
      "25-03-2016 19:16:14 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - query_lsi: [(0, 1.1012835748628467), (1, 0.72812283398049715)]\n",
      "25-03-2016 19:16:14 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - sims: [(0, 0.40757114), (1, 0.93163693), (2, 0.83416492)]\n",
      "25-03-2016 19:16:14 - <ipython-input-77-a79ba582be37> - <module> - INFO - sort_sims: [(1, 0.93163693), (2, 0.83416492), (0, 0.40757114)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 0.93163693), (2, 0.83416492), (0, 0.40757114)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [\"Shipment of gold damaged in a fire\", \"Delivery of silver arrived in a silver truck\", \n",
    " \"Shipment of gold arrived in a truck\"]\n",
    "texts = [[word for word in document.lower().split()] for document in documents]\n",
    "query = 'gold silver truck'\n",
    "gensim4texts(logger, texts, query.lower().split(), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nltkPreProcess4texts(logger, texts, stemmer=None):\n",
    "# logger: logging object\n",
    "# texts: list of texts for preprocessing with NLTK\n",
    "# stemmer: default is LancasterStemmer; PorterStemmer\n",
    "    logger.info('This is %s', sys._getframe().f_code.co_name)\n",
    "    logger.info('texts=%s', texts[0])\n",
    "# lowering case\n",
    "    texts_lower = [[word for word in document.lower().split()] for document in texts]\n",
    "    logger.debug('texts_lower[0]=%s', texts_lower[0])\n",
    "# tockenizing\n",
    "    texts_tokenized = [[word.lower() for word in nltk.word_tokenize(document)] for document in texts]\n",
    "    logger.debug('texts_tokenized[0]=%s', texts_tokenized[0])\n",
    "# filtering stopwords and punctuations\n",
    "    english_stopwords = nltk.corpus.stopwords.words('english')\n",
    "    english_stopwords.extend([',', '.', ':', ';', '?', '(', ')', '[', ']', '&', '!', '*', '@', '#', '$', '%'])\n",
    "    logger.debug('english_stopwords=%s, length=%d', english_stopwords,len(english_stopwords))\n",
    "    texts_filtered_stopwords = [[word for word in document if not word in english_stopwords] for document in texts_tokenized]\n",
    "    logger.debug('texts_filtered_stopwords[0]=%s', texts_filtered_stopwords[0])\n",
    "# stemmering with LancasterStemmer\n",
    "    if stemmer is 'porter':\n",
    "        st = nltk.PorterStemmer()\n",
    "#        st = nltk.stem.porter.PorterStemmer()\n",
    "    else:\n",
    "        st = nltk.LancasterStemmer()\n",
    "#        st = nltk.stem.lancaster.LancasterStemmer()\n",
    "    texts_stemmed = [[st.stem(word) for word in docment] for docment in texts_filtered_stopwords]\n",
    "    logger.debug('texts_stemmed[0]=%s', texts_stemmed[0])\n",
    "# eliminating words with only one occurence\n",
    "    all_stems = sum(texts_stemmed, [])\n",
    "    stems_once = set(stem for stem in set(all_stems) if all_stems.count(stem) == 1)\n",
    "    texts = [[stem for stem in text if stem not in stems_once] for text in texts_stemmed]\n",
    "    logger.debug('texts_WithMoreThanOneCounts[0]=%s', texts[0])\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-03-2016 22:02:56 - <ipython-input-77-a79ba582be37> - <module> - INFO - This is gensim4texts\n",
      "25-03-2016 22:02:56 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - texts: [['你', '认识', '那个', '和', '主席', '握手', '的', 'Python', '的哥', '吗'], ['他', '开', '一辆', '黑色', 'C++'], ['黑色', '的士'], ['我', '爱', 'Python', '和', 'C++']]\n",
      "25-03-2016 22:02:56 - dictionary - gensim.corpora.dictionary - INFO - adding document #0 to Dictionary(0 unique tokens: [])\n",
      "25-03-2016 22:02:56 - dictionary - gensim.corpora.dictionary - INFO - built Dictionary(18 unique tokens: ['的', '的哥', '的士', 'C++', '和']...) from 4 documents (total 22 corpus positions)\n",
      "25-03-2016 22:02:56 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - dictionary.token2id: {'的': 0, '的哥': 3, '的士': 15, 'C++': 10, '和': 6, '一辆': 11, '他': 13, '黑色': 12, 'Python': 1, '你': 2, '开': 14, '我': 17, '那个': 4, '认识': 7, '吗': 9, '爱': 16, '主席': 5, '握手': 8}\n",
      "25-03-2016 22:02:56 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - corpus: [[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1)], [(10, 1), (11, 1), (12, 1), (13, 1), (14, 1)], [(12, 1), (15, 1)], [(1, 1), (6, 1), (10, 1), (16, 1), (17, 1)]]\n",
      "25-03-2016 22:02:56 - tfidfmodel - gensim.models.tfidfmodel - INFO - collecting document frequencies\n",
      "25-03-2016 22:02:56 - tfidfmodel - gensim.models.tfidfmodel - INFO - PROGRESS: processing document #0\n",
      "25-03-2016 22:02:56 - tfidfmodel - gensim.models.tfidfmodel - INFO - calculating IDF weights for 4 documents and 17 features (22 matrix non-zeros)\n",
      "25-03-2016 22:02:56 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - corpus_tfidf.doc: [(0, 0.34299717028501764), (1, 0.17149858514250882), (2, 0.34299717028501764), (3, 0.34299717028501764), (4, 0.34299717028501764), (5, 0.34299717028501764), (6, 0.17149858514250882), (7, 0.34299717028501764), (8, 0.34299717028501764), (9, 0.34299717028501764)]\n",
      "25-03-2016 22:02:56 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - corpus_tfidf.doc: [(10, 0.2672612419124244), (11, 0.5345224838248488), (12, 0.2672612419124244), (13, 0.5345224838248488), (14, 0.5345224838248488)]\n",
      "25-03-2016 22:02:56 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - corpus_tfidf.doc: [(12, 0.4472135954999579), (15, 0.8944271909999159)]\n",
      "25-03-2016 22:02:56 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - corpus_tfidf.doc: [(1, 0.30151134457776363), (6, 0.30151134457776363), (10, 0.30151134457776363), (16, 0.6030226891555273), (17, 0.6030226891555273)]\n",
      "25-03-2016 22:02:56 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - tfidf.dfs: {0: 1, 1: 2, 2: 1, 3: 1, 4: 1, 5: 1, 6: 2, 7: 1, 8: 1, 9: 1, 10: 2, 11: 1, 12: 2, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1}\n",
      "25-03-2016 22:02:56 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - tfidf.idfs: {0: 2.0, 1: 1.0, 2: 2.0, 3: 2.0, 4: 2.0, 5: 2.0, 6: 1.0, 7: 2.0, 8: 2.0, 9: 2.0, 10: 1.0, 11: 2.0, 12: 1.0, 13: 2.0, 14: 2.0, 15: 2.0, 16: 2.0, 17: 2.0}\n",
      "25-03-2016 22:02:56 - lsimodel - gensim.models.lsimodel - INFO - using serial LSI version on this node\n",
      "25-03-2016 22:02:56 - lsimodel - gensim.models.lsimodel - INFO - updating model with new documents\n",
      "25-03-2016 22:02:56 - lsimodel - gensim.models.lsimodel - INFO - preparing a new chunk of documents\n",
      "25-03-2016 22:02:56 - lsimodel - gensim.models.lsimodel - DEBUG - converting corpus to csc format\n",
      "25-03-2016 22:02:56 - lsimodel - gensim.models.lsimodel - INFO - using 100 extra samples and 2 power iterations\n",
      "25-03-2016 22:02:56 - lsimodel - gensim.models.lsimodel - INFO - 1st phase: constructing (18, 102) action matrix\n",
      "25-03-2016 22:02:56 - lsimodel - gensim.models.lsimodel - INFO - orthonormalizing (18, 102) action matrix\n",
      "25-03-2016 22:02:56 - matutils - gensim.matutils - DEBUG - computing QR of (18, 102) dense matrix\n",
      "25-03-2016 22:02:56 - lsimodel - gensim.models.lsimodel - DEBUG - running 2 power iterations\n",
      "25-03-2016 22:02:56 - matutils - gensim.matutils - DEBUG - computing QR of (18, 18) dense matrix\n",
      "25-03-2016 22:02:56 - matutils - gensim.matutils - DEBUG - computing QR of (18, 18) dense matrix\n",
      "25-03-2016 22:02:56 - lsimodel - gensim.models.lsimodel - INFO - 2nd phase: running dense svd on (18, 4) matrix\n",
      "25-03-2016 22:02:56 - lsimodel - gensim.models.lsimodel - INFO - computing the final decomposition\n",
      "25-03-2016 22:02:56 - lsimodel - gensim.models.lsimodel - INFO - keeping 2 factors (discarding 44.074% of energy spectrum)\n",
      "25-03-2016 22:02:56 - lsimodel - gensim.models.lsimodel - INFO - processed documents up to #4\n",
      "25-03-2016 22:02:56 - lsimodel - gensim.models.lsimodel - INFO - topic #0(1.077): 0.383*\"的士\" + 0.344*\"黑色\" + 0.306*\"他\" + 0.306*\"一辆\" + 0.306*\"开\" + 0.303*\"C++\" + 0.300*\"爱\" + 0.300*\"我\" + 0.205*\"Python\" + 0.205*\"和\"\n",
      "25-03-2016 22:02:56 - lsimodel - gensim.models.lsimodel - INFO - topic #1(1.038): 0.462*\"的士\" + 0.320*\"黑色\" + -0.268*\"我\" + -0.268*\"爱\" + -0.236*\"和\" + -0.236*\"Python\" + -0.204*\"的哥\" + -0.204*\"那个\" + -0.204*\"握手\" + -0.204*\"吗\"\n",
      "25-03-2016 22:02:56 - lsimodel - gensim.models.lsimodel - INFO - topic #0(1.077): 0.383*\"的士\" + 0.344*\"黑色\" + 0.306*\"他\" + 0.306*\"一辆\" + 0.306*\"开\" + 0.303*\"C++\" + 0.300*\"爱\" + 0.300*\"我\" + 0.205*\"Python\" + 0.205*\"和\"\n",
      "25-03-2016 22:02:56 - lsimodel - gensim.models.lsimodel - INFO - topic #1(1.038): 0.462*\"的士\" + 0.320*\"黑色\" + -0.268*\"我\" + -0.268*\"爱\" + -0.236*\"和\" + -0.236*\"Python\" + -0.204*\"的哥\" + -0.204*\"那个\" + -0.204*\"握手\" + -0.204*\"吗\"\n",
      "25-03-2016 22:02:56 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - copus_lsi.doc: [(0, 0.37394510153659233), (1, -0.63937050640159387)]\n",
      "25-03-2016 22:02:56 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - copus_lsi.doc: [(0, 0.66330479503624273), (1, 0.36045189289304491)]\n",
      "25-03-2016 22:02:56 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - copus_lsi.doc: [(0, 0.49669142160005741), (1, 0.55632755797075595)]\n",
      "25-03-2016 22:02:56 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - copus_lsi.doc: [(0, 0.57715320478205534), (1, -0.47876910905853742)]\n",
      "25-03-2016 22:02:56 - ldamodel - gensim.models.ldamodel - INFO - using symmetric alpha at 0.5\n",
      "25-03-2016 22:02:56 - ldamodel - gensim.models.ldamodel - INFO - using symmetric eta at 0.5\n",
      "25-03-2016 22:02:56 - ldamodel - gensim.models.ldamodel - INFO - using serial LDA version on this node\n",
      "25-03-2016 22:02:56 - ldamodel - gensim.models.ldamodel - INFO - running online LDA training, 2 topics, 1 passes over the supplied corpus of 4 documents, updating model once every 4 documents, evaluating perplexity every 4 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "25-03-2016 22:02:56 - ldamodel - gensim.models.ldamodel - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "25-03-2016 22:02:56 - ldamodel - gensim.models.ldamodel - DEBUG - bound: at document #0\n",
      "25-03-2016 22:02:56 - ldamodel - gensim.models.ldamodel - INFO - -6.987 per-word bound, 126.9 perplexity estimate based on a held-out corpus of 4 documents with 8 words\n",
      "25-03-2016 22:02:56 - ldamodel - gensim.models.ldamodel - INFO - PROGRESS: pass 0, at document #4/4\n",
      "25-03-2016 22:02:56 - ldamodel - gensim.models.ldamodel - DEBUG - performing inference on a chunk of 4 documents\n",
      "25-03-2016 22:02:56 - ldamodel - gensim.models.ldamodel - DEBUG - 4/4 documents converged within 50 iterations\n",
      "25-03-2016 22:02:56 - ldamodel - gensim.models.ldamodel - DEBUG - updating topics\n",
      "25-03-2016 22:02:56 - ldamodel - gensim.models.ldamodel - INFO - topic #0 (0.500): 0.091*的士 + 0.073*黑色 + 0.061*我 + 0.060*爱 + 0.058*C++ + 0.057*开 + 0.055*他 + 0.054*一辆 + 0.053*和 + 0.053*Python\n",
      "25-03-2016 22:02:56 - ldamodel - gensim.models.ldamodel - INFO - topic #1 (0.500): 0.061*一辆 + 0.060*爱 + 0.060*C++ + 0.060*他 + 0.059*我 + 0.058*开 + 0.057*Python + 0.057*和 + 0.056*黑色 + 0.055*的\n",
      "25-03-2016 22:02:56 - ldamodel - gensim.models.ldamodel - INFO - topic diff=0.269739, rho=1.000000\n",
      "25-03-2016 22:02:56 - ldamodel - gensim.models.ldamodel - INFO - topic #0 (0.500): 0.091*的士 + 0.073*黑色 + 0.061*我 + 0.060*爱 + 0.058*C++ + 0.057*开 + 0.055*他 + 0.054*一辆 + 0.053*和 + 0.053*Python\n",
      "25-03-2016 22:02:56 - ldamodel - gensim.models.ldamodel - INFO - topic #1 (0.500): 0.061*一辆 + 0.060*爱 + 0.060*C++ + 0.060*他 + 0.059*我 + 0.058*开 + 0.057*Python + 0.057*和 + 0.056*黑色 + 0.055*的\n",
      "25-03-2016 22:02:56 - docsim - gensim.similarities.docsim - WARNING - scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "25-03-2016 22:02:56 - docsim - gensim.similarities.docsim - INFO - creating matrix with 4 documents and 2 features\n",
      "25-03-2016 22:02:56 - docsim - gensim.similarities.docsim - DEBUG - PROGRESS: at document #0/4\n",
      "25-03-2016 22:02:56 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - query_bow: [(0, 1)]\n",
      "25-03-2016 22:02:56 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - query_lsi: [(0, 0.11060736452430375), (1, -0.2035400470959986)]\n",
      "25-03-2016 22:02:56 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - sims: [(0, 0.99848497), (1, 0.018948048), (2, -0.31816125), (3, 0.92187905)]\n",
      "25-03-2016 22:02:56 - <ipython-input-77-a79ba582be37> - <module> - INFO - sort_sims: [(0, 0.99848497), (3, 0.92187905), (1, 0.018948048), (2, -0.31816125)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['你', '认识', '那个', '和', '主席', '握手', '的', 'Python', '的哥', '吗'], ['他', '开', '一辆', '黑色', 'C++'], ['黑色', '的士'], ['我', '爱', 'Python', '和', 'C++']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0.99848497), (3, 0.92187905), (1, 0.018948048), (2, -0.31816125)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [\"你 认识 那个 和 主席 握手 的 Python 的哥 吗\", \"他 开 一辆 黑色 C++\", \"黑色 的士\", \"我 爱 Python 和 C++\"]\n",
    "texts = [[word for word in document.split()] for document in documents]\n",
    "print(texts)\n",
    "query = u'红色 的 Python'\n",
    "gensim4texts(logger, texts, query.lower().split(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-03-2016 22:03:02 - <ipython-input-77-a79ba582be37> - <module> - INFO - This is gensim4texts\n",
      "25-03-2016 22:03:02 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - texts: [['运', '送', '黄金', '的', '车', '在', '火', '中', '受损'], ['一辆', '银色', '的', '运', '银', '卡车', '到达'], ['运送', '黄金', '的', '卡车', '抵达']]\n",
      "25-03-2016 22:03:02 - dictionary - gensim.corpora.dictionary - INFO - adding document #0 to Dictionary(0 unique tokens: [])\n",
      "25-03-2016 22:03:02 - dictionary - gensim.corpora.dictionary - INFO - built Dictionary(16 unique tokens: ['银', '的', '一辆', '火', '运送']...) from 3 documents (total 21 corpus positions)\n",
      "25-03-2016 22:03:02 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - dictionary.token2id: {'银': 9, '的': 1, '一辆': 10, '火': 6, '运送': 14, '车': 5, '受损': 8, '银色': 11, '卡车': 12, '抵达': 15, '运': 0, '在': 4, '黄金': 2, '送': 3, '到达': 13, '中': 7}\n",
      "25-03-2016 22:03:02 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - corpus: [[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)], [(0, 1), (1, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1)], [(1, 1), (2, 1), (12, 1), (14, 1), (15, 1)]]\n",
      "25-03-2016 22:03:02 - tfidfmodel - gensim.models.tfidfmodel - INFO - collecting document frequencies\n",
      "25-03-2016 22:03:02 - tfidfmodel - gensim.models.tfidfmodel - INFO - PROGRESS: processing document #0\n",
      "25-03-2016 22:03:02 - tfidfmodel - gensim.models.tfidfmodel - INFO - calculating IDF weights for 3 documents and 15 features (21 matrix non-zeros)\n",
      "25-03-2016 22:03:02 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - corpus_tfidf.doc: [(0, 0.1473639561879945), (2, 0.1473639561879945), (3, 0.39928430322959224), (4, 0.39928430322959224), (5, 0.39928430322959224), (6, 0.39928430322959224), (7, 0.39928430322959224), (8, 0.39928430322959224)]\n",
      "25-03-2016 22:03:02 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - corpus_tfidf.doc: [(0, 0.17855490118826328), (9, 0.48379652089574265), (10, 0.48379652089574265), (11, 0.48379652089574265), (12, 0.17855490118826328), (13, 0.48379652089574265)]\n",
      "25-03-2016 22:03:02 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - corpus_tfidf.doc: [(2, 0.2448297500958463), (12, 0.2448297500958463), (14, 0.6633689723434505), (15, 0.6633689723434505)]\n",
      "25-03-2016 22:03:02 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - tfidf.dfs: {0: 2, 1: 3, 2: 2, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 2, 13: 1, 14: 1, 15: 1}\n",
      "25-03-2016 22:03:02 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - tfidf.idfs: {0: 0.5849625007211562, 1: 0.0, 2: 0.5849625007211562, 3: 1.5849625007211563, 4: 1.5849625007211563, 5: 1.5849625007211563, 6: 1.5849625007211563, 7: 1.5849625007211563, 8: 1.5849625007211563, 9: 1.5849625007211563, 10: 1.5849625007211563, 11: 1.5849625007211563, 12: 0.5849625007211562, 13: 1.5849625007211563, 14: 1.5849625007211563, 15: 1.5849625007211563}\n",
      "25-03-2016 22:03:02 - lsimodel - gensim.models.lsimodel - INFO - using serial LSI version on this node\n",
      "25-03-2016 22:03:02 - lsimodel - gensim.models.lsimodel - INFO - updating model with new documents\n",
      "25-03-2016 22:03:02 - lsimodel - gensim.models.lsimodel - INFO - preparing a new chunk of documents\n",
      "25-03-2016 22:03:02 - lsimodel - gensim.models.lsimodel - DEBUG - converting corpus to csc format\n",
      "25-03-2016 22:03:02 - lsimodel - gensim.models.lsimodel - INFO - using 100 extra samples and 2 power iterations\n",
      "25-03-2016 22:03:02 - lsimodel - gensim.models.lsimodel - INFO - 1st phase: constructing (16, 102) action matrix\n",
      "25-03-2016 22:03:02 - lsimodel - gensim.models.lsimodel - INFO - orthonormalizing (16, 102) action matrix\n",
      "25-03-2016 22:03:02 - matutils - gensim.matutils - DEBUG - computing QR of (16, 102) dense matrix\n",
      "25-03-2016 22:03:02 - lsimodel - gensim.models.lsimodel - DEBUG - running 2 power iterations\n",
      "25-03-2016 22:03:02 - matutils - gensim.matutils - DEBUG - computing QR of (16, 16) dense matrix\n",
      "25-03-2016 22:03:02 - matutils - gensim.matutils - DEBUG - computing QR of (16, 16) dense matrix\n",
      "25-03-2016 22:03:02 - lsimodel - gensim.models.lsimodel - INFO - 2nd phase: running dense svd on (16, 3) matrix\n",
      "25-03-2016 22:03:02 - lsimodel - gensim.models.lsimodel - INFO - computing the final decomposition\n",
      "25-03-2016 22:03:02 - lsimodel - gensim.models.lsimodel - INFO - keeping 2 factors (discarding 31.810% of energy spectrum)\n",
      "25-03-2016 22:03:02 - lsimodel - gensim.models.lsimodel - INFO - processed documents up to #3\n",
      "25-03-2016 22:03:02 - lsimodel - gensim.models.lsimodel - INFO - topic #0(1.035): 0.399*\"抵达\" + 0.399*\"运送\" + 0.270*\"银\" + 0.270*\"到达\" + 0.270*\"银色\" + 0.270*\"一辆\" + 0.247*\"卡车\" + 0.222*\"黄金\" + 0.204*\"送\" + 0.204*\"中\"\n",
      "25-03-2016 22:03:02 - lsimodel - gensim.models.lsimodel - INFO - topic #1(0.987): -0.325*\"送\" + -0.325*\"受损\" + -0.325*\"车\" + -0.325*\"在\" + -0.325*\"中\" + -0.325*\"火\" + 0.283*\"一辆\" + 0.283*\"银\" + 0.283*\"银色\" + 0.283*\"到达\"\n",
      "25-03-2016 22:03:02 - lsimodel - gensim.models.lsimodel - INFO - topic #0(1.035): 0.399*\"抵达\" + 0.399*\"运送\" + 0.270*\"银\" + 0.270*\"到达\" + 0.270*\"银色\" + 0.270*\"一辆\" + 0.247*\"卡车\" + 0.222*\"黄金\" + 0.204*\"送\" + 0.204*\"中\"\n",
      "25-03-2016 22:03:02 - lsimodel - gensim.models.lsimodel - INFO - topic #1(0.987): -0.325*\"送\" + -0.325*\"受损\" + -0.325*\"车\" + -0.325*\"在\" + -0.325*\"中\" + -0.325*\"火\" + 0.283*\"一辆\" + 0.283*\"银\" + 0.283*\"银色\" + 0.283*\"到达\"\n",
      "25-03-2016 22:03:02 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - copus_lsi.doc: [(0, 0.54712043867089843), (1, -0.7929086034696663)]\n",
      "25-03-2016 22:03:02 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - copus_lsi.doc: [(0, 0.59755302839720426), (1, 0.56994113743150598)]\n",
      "25-03-2016 22:03:02 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - copus_lsi.doc: [(0, 0.64404849901378536), (1, 0.14478172128138742)]\n",
      "25-03-2016 22:03:02 - ldamodel - gensim.models.ldamodel - INFO - using symmetric alpha at 0.5\n",
      "25-03-2016 22:03:02 - ldamodel - gensim.models.ldamodel - INFO - using symmetric eta at 0.5\n",
      "25-03-2016 22:03:02 - ldamodel - gensim.models.ldamodel - INFO - using serial LDA version on this node\n",
      "25-03-2016 22:03:02 - ldamodel - gensim.models.ldamodel - INFO - running online LDA training, 2 topics, 1 passes over the supplied corpus of 3 documents, updating model once every 3 documents, evaluating perplexity every 3 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "25-03-2016 22:03:02 - ldamodel - gensim.models.ldamodel - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "25-03-2016 22:03:02 - ldamodel - gensim.models.ldamodel - DEBUG - bound: at document #0\n",
      "25-03-2016 22:03:02 - ldamodel - gensim.models.ldamodel - INFO - -7.036 per-word bound, 131.2 perplexity estimate based on a held-out corpus of 3 documents with 6 words\n",
      "25-03-2016 22:03:02 - ldamodel - gensim.models.ldamodel - INFO - PROGRESS: pass 0, at document #3/3\n",
      "25-03-2016 22:03:02 - ldamodel - gensim.models.ldamodel - DEBUG - performing inference on a chunk of 3 documents\n",
      "25-03-2016 22:03:02 - ldamodel - gensim.models.ldamodel - DEBUG - 2/3 documents converged within 50 iterations\n",
      "25-03-2016 22:03:02 - ldamodel - gensim.models.ldamodel - DEBUG - updating topics\n",
      "25-03-2016 22:03:02 - ldamodel - gensim.models.ldamodel - INFO - topic #0 (0.500): 0.083*抵达 + 0.082*运送 + 0.067*一辆 + 0.067*到达 + 0.066*银 + 0.065*黄金 + 0.065*卡车 + 0.064*银色 + 0.058*受损 + 0.057*火\n",
      "25-03-2016 22:03:02 - ldamodel - gensim.models.ldamodel - INFO - topic #1 (0.500): 0.067*送 + 0.066*车 + 0.066*在 + 0.066*银色 + 0.065*中 + 0.065*火 + 0.065*运送 + 0.064*受损 + 0.064*抵达 + 0.064*银\n",
      "25-03-2016 22:03:02 - ldamodel - gensim.models.ldamodel - INFO - topic diff=0.304079, rho=1.000000\n",
      "25-03-2016 22:03:02 - ldamodel - gensim.models.ldamodel - INFO - topic #0 (0.500): 0.083*抵达 + 0.082*运送 + 0.067*一辆 + 0.067*到达 + 0.066*银 + 0.065*黄金 + 0.065*卡车 + 0.064*银色 + 0.058*受损 + 0.057*火\n",
      "25-03-2016 22:03:02 - ldamodel - gensim.models.ldamodel - INFO - topic #1 (0.500): 0.067*送 + 0.066*车 + 0.066*在 + 0.066*银色 + 0.065*中 + 0.065*火 + 0.065*运送 + 0.064*受损 + 0.064*抵达 + 0.064*银\n",
      "25-03-2016 22:03:02 - docsim - gensim.similarities.docsim - WARNING - scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "25-03-2016 22:03:02 - docsim - gensim.similarities.docsim - INFO - creating matrix with 3 documents and 2 features\n",
      "25-03-2016 22:03:02 - docsim - gensim.similarities.docsim - DEBUG - PROGRESS: at document #0/3\n",
      "25-03-2016 22:03:02 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - query_bow: [(2, 1), (9, 1), (12, 1)]\n",
      "25-03-2016 22:03:02 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - query_lsi: [(0, 0.73914660558026735), (1, 0.34022510170526077)]\n",
      "25-03-2016 22:03:02 - <ipython-input-77-a79ba582be37> - <module> - DEBUG - sims: [(0, 0.23582897), (1, 0.9648906), (2, 0.97292513)]\n",
      "25-03-2016 22:03:02 - <ipython-input-77-a79ba582be37> - <module> - INFO - sort_sims: [(2, 0.97292513), (1, 0.9648906), (0, 0.23582897)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['运', '送', '黄金', '的', '车', '在', '火', '中', '受损'], ['一辆', '银色', '的', '运', '银', '卡车', '到达'], ['运送', '黄金', '的', '卡车', '抵达']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2, 0.97292513), (1, 0.9648906), (0, 0.23582897)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [\"运 送 黄金 的 车 在 火 中 受损\", \"一辆 银色 的 运 银 卡车 到达\", \"运送 黄金 的 卡车 抵达\"]\n",
    "texts = [[word for word in document.split()] for document in documents]\n",
    "print(texts)\n",
    "query = u'黄金 银 卡车'\n",
    "gensim4texts(logger, texts, query.split(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fn = '../cjzpyml/cjzpynlp/data/coursera_corpus'\n",
    "courses = [line.strip() for line in open(fn)]\n",
    "courses_name = [course.split('\\t')[0] for course in courses]\n",
    "logger.debug('courses_name[0:10]=%s', courses_name[0:10])\n",
    "\n",
    "texts = nltkPreProcess4texts(logger, courses) #default stemmer is Lancaster\n",
    "sims = gensim4texts(logger, texts, texts[210], 10)\n",
    "for i, j in enumerate(sims[0:10]):\n",
    "    logger.info('(#,similar_course_name,sims)=(%d,%s,%f)', i, courses_name[j[0]], j[1])\n",
    "\n",
    "texts = nltkPreProcess4texts(logger, courses, stemmer='porter')\n",
    "sims = gensim4texts(logger, texts, texts[210], 10)\n",
    "for i, j in enumerate(sims[0:10]):\n",
    "    logger.info('(#,similar_course_name,sims)=(%d,%s,%f)', i, courses_name[j[0]], j[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = '../cjzpyml/cjzpynlp/data/coursera_corpus_c'\n",
    "courses = [line.strip() for line in open(fn)]\n",
    "courses_name = [course.split('\\t')[0] for course in courses]\n",
    "logger.debug('courses_name[0:10]=%s', courses_name[0:10])\n",
    "\n",
    "texts = nltkPreProcess4texts(logger, courses) #default stemmer is Lancaster\n",
    "sims = gensim4texts(logger, texts, texts[210], 10)\n",
    "for i, j in enumerate(sims[0:10]):\n",
    "    logger.info('(#,similar_course_name,sims)=(%d,%s,%f)', i, courses_name[j[0]], j[1])\n",
    "\n",
    "texts = nltkPreProcess4texts(logger, courses, stemmer='porter')\n",
    "sims = gensim4texts(logger, texts, texts[210], 10)\n",
    "for i, j in enumerate(sims[0:10]):\n",
    "    logger.info('(#,similar_course_name,sims)=(%d,%s,%f)', i, courses_name[j[0]], j[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyCorpus(object):\n",
    "    def __init__(self, logger, fn):\n",
    "        self.fn = fn\n",
    "        self.logger = logger\n",
    "        self.stoplist = set('for a of the and to in'.split())\n",
    "        self.logger.info('I am at class %s', self)\n",
    "    \n",
    "    def getDictionary1(self):\n",
    "        documents = [\"Human machine interface for lab abc computer applications\",\n",
    "                    \"A survey of user opinion of computer system response time\",\n",
    "                    \"The EPS user interface management system\",\n",
    "                    \"System and human system engineering testing of EPS\",\n",
    "                    \"Relation of user perceived response time to error measurement\",\n",
    "                    \"The generation of random binary unordered trees\",\n",
    "                    \"The intersection graph of paths in trees\",\n",
    "                    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "                    \"Graph minors A survey\"]\n",
    "# remove common words and tokenize\n",
    "        texts = [[word for word in document.lower().split() if word not in self.stoplist] for document in documents]\n",
    "# remove words that appear only once\n",
    "        all_tokens = sum(texts, [])\n",
    "        tokens_once = set(word for word in set(all_tokens) if all_tokens.count(word) == 1)\n",
    "        texts = [[word for word in text if word not in tokens_once] for text in texts]\n",
    "        self.dictionary1 = gensim.corpora.Dictionary(texts)\n",
    "#        self.dictionary1.save('dict_tmp.dict') # store the dictionary, for future reference\n",
    "\n",
    "    def getDictionary(self):\n",
    "# collect statistics about all tokens\n",
    "        self.dictionary = gensim.corpora.Dictionary(line.lower().strip().split() for line in open(self.fn))\n",
    "# remove stop words and words that appear only once\n",
    "        stop_ids = [self.dictionary.token2id[stopword] for stopword in self.stoplist if stopword in self.dictionary.token2id]\n",
    "        once_ids = [tokenid for tokenid, docfreq in self.dictionary.dfs.items() if docfreq == 1]\n",
    "        self.dictionary.filter_tokens(stop_ids + once_ids) # remove stop words and words that appear only once\n",
    "        self.dictionary.compactify() # remove gaps in id sequence after words that were removed\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.getDictionary1()\n",
    "        self.getDictionary()\n",
    "        for line in open(self.fn):\n",
    "# assume there's one document per line, tokens separated by whitespace\n",
    "            yield self.dictionary.doc2bow(line.lower().strip().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-03-2016 22:03:37 - <ipython-input-83-1f1d0e5492ae> - <module> - INFO - I am at class <__main__.MyCorpus object at 0x7f98f89d2048>\n",
      "25-03-2016 22:03:37 - dictionary - gensim.corpora.dictionary - INFO - adding document #0 to Dictionary(0 unique tokens: [])\n",
      "25-03-2016 22:03:37 - dictionary - gensim.corpora.dictionary - INFO - built Dictionary(12 unique tokens: ['computer', 'trees', 'eps', 'user', 'graph']...) from 9 documents (total 29 corpus positions)\n",
      "25-03-2016 22:03:37 - dictionary - gensim.corpora.dictionary - INFO - adding document #0 to Dictionary(0 unique tokens: [])\n",
      "25-03-2016 22:03:37 - dictionary - gensim.corpora.dictionary - INFO - built Dictionary(58 unique tokens: ['city', 'rock', 'a', 'gas', 'highway,']...) from 4 documents (total 74 corpus positions)\n",
      "25-03-2016 22:03:37 - dictionary - gensim.corpora.dictionary - DEBUG - rebuilding dictionary, shrinking gaps\n",
      "25-03-2016 22:03:37 - dictionary - gensim.corpora.dictionary - DEBUG - rebuilding dictionary, shrinking gaps\n",
      "25-03-2016 22:03:37 - <ipython-input-84-8713783ad93f> - <module> - INFO - vector=[]\n",
      "25-03-2016 22:03:37 - <ipython-input-84-8713783ad93f> - <module> - INFO - vector=[(0, 1)]\n",
      "25-03-2016 22:03:37 - <ipython-input-84-8713783ad93f> - <module> - INFO - vector=[(0, 1)]\n",
      "25-03-2016 22:03:37 - <ipython-input-84-8713783ad93f> - <module> - INFO - vector=[]\n"
     ]
    }
   ],
   "source": [
    "fn = '../cjzpyml/cjzpynlp/data/mycorpus.txt'\n",
    "corpus_memory_friendly = MyCorpus(logger, fn) # doesn't load the corpus into memory!\n",
    "for vector in corpus_memory_friendly: # load one vector into memory at a time\n",
    "    logger.info('vector=%s', vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-03-2016 22:03:38 - <ipython-input-83-1f1d0e5492ae> - <module> - INFO - I am at class <__main__.MyCorpus object at 0x7f98f92cee48>\n",
      "25-03-2016 22:03:38 - dictionary - gensim.corpora.dictionary - INFO - adding document #0 to Dictionary(0 unique tokens: [])\n",
      "25-03-2016 22:03:38 - dictionary - gensim.corpora.dictionary - INFO - built Dictionary(12 unique tokens: ['computer', 'trees', 'eps', 'user', 'graph']...) from 9 documents (total 29 corpus positions)\n",
      "25-03-2016 22:03:38 - dictionary - gensim.corpora.dictionary - INFO - adding document #0 to Dictionary(0 unique tokens: [])\n",
      "25-03-2016 22:03:38 - dictionary - gensim.corpora.dictionary - INFO - built Dictionary(50 unique tokens: ['a', 'time', 'trees', 'interface', 'widths']...) from 13 documents (total 94 corpus positions)\n",
      "25-03-2016 22:03:38 - dictionary - gensim.corpora.dictionary - DEBUG - rebuilding dictionary, shrinking gaps\n",
      "25-03-2016 22:03:38 - dictionary - gensim.corpora.dictionary - DEBUG - rebuilding dictionary, shrinking gaps\n",
      "25-03-2016 22:03:38 - <ipython-input-85-9d3985a4c5a7> - <module> - INFO - vector=[(12, 1), (13, 1)]\n",
      "25-03-2016 22:03:38 - <ipython-input-85-9d3985a4c5a7> - <module> - INFO - vector=[(6, 1), (10, 1), (11, 2)]\n",
      "25-03-2016 22:03:38 - <ipython-input-85-9d3985a4c5a7> - <module> - INFO - vector=[(6, 1), (10, 1), (12, 1), (13, 1)]\n",
      "25-03-2016 22:03:38 - <ipython-input-85-9d3985a4c5a7> - <module> - INFO - vector=[(10, 1), (11, 1), (12, 1)]\n",
      "25-03-2016 22:03:38 - <ipython-input-85-9d3985a4c5a7> - <module> - INFO - vector=[(3, 1), (7, 1), (9, 1)]\n",
      "25-03-2016 22:03:38 - <ipython-input-85-9d3985a4c5a7> - <module> - INFO - vector=[(0, 1), (1, 1), (8, 1), (9, 1), (15, 1), (16, 1)]\n",
      "25-03-2016 22:03:38 - <ipython-input-85-9d3985a4c5a7> - <module> - INFO - vector=[(3, 1), (8, 1), (14, 1), (16, 1)]\n",
      "25-03-2016 22:03:38 - <ipython-input-85-9d3985a4c5a7> - <module> - INFO - vector=[(7, 1), (8, 2), (14, 1)]\n",
      "25-03-2016 22:03:38 - <ipython-input-85-9d3985a4c5a7> - <module> - INFO - vector=[(1, 1), (15, 1), (16, 1)]\n",
      "25-03-2016 22:03:38 - <ipython-input-85-9d3985a4c5a7> - <module> - INFO - vector=[(2, 1)]\n",
      "25-03-2016 22:03:38 - <ipython-input-85-9d3985a4c5a7> - <module> - INFO - vector=[(2, 1), (4, 1)]\n",
      "25-03-2016 22:03:38 - <ipython-input-85-9d3985a4c5a7> - <module> - INFO - vector=[(2, 1), (4, 1), (5, 1)]\n",
      "25-03-2016 22:03:38 - <ipython-input-85-9d3985a4c5a7> - <module> - INFO - vector=[(0, 1), (4, 1), (5, 1)]\n"
     ]
    }
   ],
   "source": [
    "fn = '../cjzpyml/cjzpynlp/data/mycorpus1.txt'\n",
    "corpus_memory_friendly = MyCorpus(logger, fn) # doesn't load the corpus into memory!\n",
    "for vector in corpus_memory_friendly: # load one vector into memory at a time\n",
    "    logger.info('vector=%s', vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
